{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier,HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('creditcard.csv').drop(['Time'],axis=1)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "target = 'Class'\n",
    "\n",
    "y_train = train_df[target]\n",
    "x_train = train_df.copy().drop([target],axis=1)\n",
    "\n",
    "y_test = test_df[target]\n",
    "x_test = test_df.copy().drop([target],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def rf_param_function(trial):\n",
    "    params = {\n",
    "        \"n_estimators\":trial.suggest_int(\"n_estiamtors\",100,500,step=100),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def outer_objective(clf,param_function):\n",
    "    def inner_objective(trial):\n",
    "        params = param_function(trial)\n",
    "        model = clf.set_params(**params).fit(x_train,y_train)\n",
    "\n",
    "        pred = model.predict(x_test)\n",
    "\n",
    "        f1 = f1_score(pred,y_test)\n",
    "\n",
    "        return f1\n",
    "    return inner_objective"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(outer_objective(RandomForestClassifier(),rf_param_function),n_trials=10)\n",
    "print(study.best_value)\n",
    "print(study.best_params)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2022-03-01 08:14:00,830]\u001b[0m A new study created in memory with name: no-name-0fb78fa5-d09c-4dcd-80ae-60c5557e971e\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:16:24,512]\u001b[0m Trial 0 finished with value: 0.8121212121212121 and parameters: {'n_estiamtors': 200, 'max_depth': 5}. Best is trial 0 with value: 0.8121212121212121.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:18:30,499]\u001b[0m Trial 1 finished with value: 0.7125000000000001 and parameters: {'n_estiamtors': 300, 'max_depth': 3}. Best is trial 0 with value: 0.8121212121212121.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:25:35,224]\u001b[0m Trial 2 finished with value: 0.8554216867469878 and parameters: {'n_estiamtors': 200, 'max_depth': 20}. Best is trial 2 with value: 0.8554216867469878.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:36:32,136]\u001b[0m Trial 3 finished with value: 0.8536585365853658 and parameters: {'n_estiamtors': 400, 'max_depth': 13}. Best is trial 2 with value: 0.8554216867469878.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:40:11,836]\u001b[0m Trial 4 finished with value: 0.8170731707317074 and parameters: {'n_estiamtors': 300, 'max_depth': 6}. Best is trial 2 with value: 0.8554216867469878.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:51:17,418]\u001b[0m Trial 5 finished with value: 0.8606060606060607 and parameters: {'n_estiamtors': 400, 'max_depth': 16}. Best is trial 5 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:53:16,185]\u001b[0m Trial 6 finished with value: 0.6838709677419355 and parameters: {'n_estiamtors': 500, 'max_depth': 2}. Best is trial 5 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 08:59:51,624]\u001b[0m Trial 7 finished with value: 0.834355828220859 and parameters: {'n_estiamtors': 500, 'max_depth': 7}. Best is trial 5 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:03:11,357]\u001b[0m Trial 8 finished with value: 0.8433734939759036 and parameters: {'n_estiamtors': 100, 'max_depth': 17}. Best is trial 5 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:05:33,637]\u001b[0m Trial 9 finished with value: 0.7204968944099378 and parameters: {'n_estiamtors': 400, 'max_depth': 3}. Best is trial 5 with value: 0.8606060606060607.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8606060606060607\n",
      "{'n_estiamtors': 400, 'max_depth': 16}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def svc_param_function(trial):\n",
    "    params = {\n",
    "        \"C\":trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def hgbc_param_function(trial):\n",
    "    params = {\n",
    "        \"max_iter\":trial.suggest_int(\"max_iter\",100,500,step=10),\n",
    "        \"max_depth\":trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
    "    }\n",
    "    return params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model_list = [\n",
    "    [RandomForestClassifier(),rf_param_function],\n",
    "    [SVC(gamma='auto'),svc_param_function],\n",
    "    [HistGradientBoostingClassifier(),hgbc_param_function]\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for i in model_list:\n",
    "\n",
    "    model_name = type(i[0]).__name__\n",
    "    print(model_name)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(outer_objective(i[0],i[1]),n_trials=10)\n",
    "\n",
    "    print(study.best_value)\n",
    "    print(study.best_params)\n",
    "\n",
    "    data = {\"model\":[model_name],\"score\":[study.best_value]}\n",
    "    params=study.best_params\n",
    "    for key, value in params.items():\n",
    "        params.update({key:[value]})\n",
    "    updated = {**data, **params}\n",
    "    \n",
    "    results = results.append(pd.DataFrame(updated),ignore_index=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2022-03-01 09:05:33,766]\u001b[0m A new study created in memory with name: no-name-bd32ec35-bc11-4148-bb73-0bd173c6beef\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestClassifier\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2022-03-01 09:06:45,904]\u001b[0m Trial 0 finished with value: 0.6838709677419355 and parameters: {'n_estiamtors': 300, 'max_depth': 2}. Best is trial 0 with value: 0.6838709677419355.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:09:43,438]\u001b[0m Trial 1 finished with value: 0.8121212121212121 and parameters: {'n_estiamtors': 300, 'max_depth': 5}. Best is trial 1 with value: 0.8121212121212121.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:15:44,504]\u001b[0m Trial 2 finished with value: 0.8466257668711656 and parameters: {'n_estiamtors': 400, 'max_depth': 8}. Best is trial 2 with value: 0.8466257668711656.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:16:58,480]\u001b[0m Trial 3 finished with value: 0.6753246753246752 and parameters: {'n_estiamtors': 300, 'max_depth': 2}. Best is trial 2 with value: 0.8466257668711656.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:32:31,001]\u001b[0m Trial 4 finished with value: 0.8606060606060607 and parameters: {'n_estiamtors': 500, 'max_depth': 24}. Best is trial 4 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:33:18,746]\u001b[0m Trial 5 finished with value: 0.6838709677419355 and parameters: {'n_estiamtors': 200, 'max_depth': 2}. Best is trial 4 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:46:35,427]\u001b[0m Trial 6 finished with value: 0.8606060606060607 and parameters: {'n_estiamtors': 500, 'max_depth': 15}. Best is trial 4 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:47:44,129]\u001b[0m Trial 7 finished with value: 0.7361963190184049 and parameters: {'n_estiamtors': 200, 'max_depth': 3}. Best is trial 4 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 09:59:52,492]\u001b[0m Trial 8 finished with value: 0.8606060606060607 and parameters: {'n_estiamtors': 400, 'max_depth': 20}. Best is trial 4 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:08:02,223]\u001b[0m Trial 9 finished with value: 0.8536585365853658 and parameters: {'n_estiamtors': 400, 'max_depth': 11}. Best is trial 4 with value: 0.8606060606060607.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:08:02,268]\u001b[0m A new study created in memory with name: no-name-f40f2fbb-fba3-4493-9507-2a35b91baecf\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8606060606060607\n",
      "{'n_estiamtors': 500, 'max_depth': 24}\n",
      "SVC\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2022-03-01 10:10:13,468]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'C': 0.007360951171576561}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:11:19,956]\u001b[0m Trial 1 finished with value: 0.48120300751879713 and parameters: {'C': 198125.6234198046}. Best is trial 1 with value: 0.48120300751879713.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:12:26,087]\u001b[0m Trial 2 finished with value: 0.48120300751879713 and parameters: {'C': 22644351.218810868}. Best is trial 1 with value: 0.48120300751879713.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:13:29,489]\u001b[0m Trial 3 finished with value: 0.48120300751879713 and parameters: {'C': 69845.32430646139}. Best is trial 1 with value: 0.48120300751879713.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:29:28,966]\u001b[0m Trial 4 finished with value: 0.4925373134328359 and parameters: {'C': 17516.317349967412}. Best is trial 4 with value: 0.4925373134328359.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:30:37,434]\u001b[0m Trial 5 finished with value: 0.48120300751879713 and parameters: {'C': 325791.62742608605}. Best is trial 4 with value: 0.4925373134328359.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:30:55,738]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'C': 3.2962403215140936e-08}. Best is trial 4 with value: 0.4925373134328359.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 10:56:58,174]\u001b[0m Trial 7 finished with value: 0.45000000000000007 and parameters: {'C': 0.7892913767187991}. Best is trial 4 with value: 0.4925373134328359.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:15:18,707]\u001b[0m Trial 8 finished with value: 0.423728813559322 and parameters: {'C': 0.7527022465536494}. Best is trial 4 with value: 0.4925373134328359.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:06,692]\u001b[0m Trial 9 finished with value: 0.5116279069767442 and parameters: {'C': 54.96557623903949}. Best is trial 9 with value: 0.5116279069767442.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:06,807]\u001b[0m A new study created in memory with name: no-name-1c7cecb9-7c9c-4513-91f2-fbffe0a62358\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5116279069767442\n",
      "{'C': 54.96557623903949}\n",
      "HistGradientBoostingClassifier\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2022-03-01 11:33:08,878]\u001b[0m Trial 0 finished with value: 0.7590361445783131 and parameters: {'max_iter': 440, 'max_depth': 2}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:10,586]\u001b[0m Trial 1 finished with value: 0.7317073170731706 and parameters: {'max_iter': 160, 'max_depth': 2}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:12,495]\u001b[0m Trial 2 finished with value: 0.6 and parameters: {'max_iter': 130, 'max_depth': 18}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:14,168]\u001b[0m Trial 3 finished with value: 0.47457627118644063 and parameters: {'max_iter': 320, 'max_depth': 4}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:15,868]\u001b[0m Trial 4 finished with value: 0.7368421052631579 and parameters: {'max_iter': 380, 'max_depth': 4}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:17,565]\u001b[0m Trial 5 finished with value: 0.6907216494845362 and parameters: {'max_iter': 120, 'max_depth': 3}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:19,285]\u001b[0m Trial 6 finished with value: 0.6395939086294415 and parameters: {'max_iter': 390, 'max_depth': 22}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:20,869]\u001b[0m Trial 7 finished with value: 0.4864864864864865 and parameters: {'max_iter': 420, 'max_depth': 3}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:22,561]\u001b[0m Trial 8 finished with value: 0.3878787878787879 and parameters: {'max_iter': 260, 'max_depth': 7}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-01 11:33:24,081]\u001b[0m Trial 9 finished with value: 0.4903225806451614 and parameters: {'max_iter': 490, 'max_depth': 4}. Best is trial 0 with value: 0.7590361445783131.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7590361445783131\n",
      "{'max_iter': 440, 'max_depth': 2}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>n_estiamtors</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>C</th>\n",
       "      <th>max_iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.860606</td>\n",
       "      <td>500.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.965576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model     score  n_estiamtors  max_depth  \\\n",
       "0          RandomForestClassifier  0.860606         500.0       24.0   \n",
       "1                             SVC  0.511628           NaN        NaN   \n",
       "2  HistGradientBoostingClassifier  0.759036           NaN        2.0   \n",
       "\n",
       "           C  max_iter  \n",
       "0        NaN       NaN  \n",
       "1  54.965576       NaN  \n",
       "2        NaN     440.0  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}